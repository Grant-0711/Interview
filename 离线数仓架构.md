加入公司的时候公司主要做的是离线业务

# 我们的数据来源

主要有两部分，日志数据是前端埋点产生的日志数据，业务数据是

javaEE后台产生

# 先大概介绍一下采集系统的框架，

日志数据方面，埋点用户行为数据采集到之后使用了nginx来达到负载均衡的目的，让每个节点均衡处理一点数据量，之后数据来到日志服务器，日志服务器的java程序把数据落盘成文件

日志服务器设置了两个月的保留时间

之后是日志服务器数据同步到hdfs的通道，我们公司采用的是两层flume+kafka的模式，也就是第一层flume先采集到数据，发到kafka，然后第二层flume消费kafka的数据同步到hdfs

中间加一层kafka的目的是削峰，遇到一些网站活动例如秒杀之类的，数据量会

比平时高，大概差不多每秒一万多条数据，这样的话早期没有采用kafka削峰的时候是出现过flume经常挂掉的情况，因此加一层kafka来削峰和解耦

# 第一层flume展开？视频4分钟开始11分52结束

# kafka展开？12分开始

# 第二层flume展开？23分22秒开始

采集通道结束 24分54秒

# 数据采集到hdfs曾经也遇到了小文件的问题 hdfs sink 调优



同时也考虑了hdfs小文件处理的一些方法，主要有三种：

​	①采用har文件格式归档，多个小文件打包成一个har包

​	②后续计算处理的时候用combineTextInputformat

​	③开启JVM重用 一般设置为10 左右



遇到的一些问题解决，flume，kafka，如何解决



# 然后介绍一下业务数据的采集通道

主要用的组件是Sqoop，

# sqoop展开？

这边主要遇到的一个问题就是null值存储的问题

这个主要是因为mysql和hive底层对null值的存储格式不同，hive底层是/n

解决的话是设置了两个参数

```shell
--null-string '\\N' \
--null-non-string '\\N'
```

# sqoop调优 30分54秒



整个采集的架构就是以上



下面介绍下离线数仓的搭建

当时参考了很多资料，也参考了数据仓库工具箱这本书的相关知识，建模方向我们公司也主要参考了阿里云的数仓架构，主要包括了ods，dwd，dws，ads层，我们额外依据指标分类又添加了dwt层



ods层主要做的是保持数据原貌，做一个数据的备份，从采集到的数据写入方式时load data inpath。。关于ods层建表方面我们创建的是分区表，按天分区，这主要是考虑到查询数据时避免全表扫描，数据存储方面也采用了压缩

# ods展开？

# 然后是dwd层，

这一层是花了比较多的时间，主要是做了数据清洗，是通过写hql的方式来做的。具体操作例如去重，字段解析，字段解析主要是针对日志数据，当时是自定义了udtf函数来实现，然后是核心字段的处理，有空字段的处理掉，还有就是脏数据和过滤，脏数据后期的比例大概是万分之一，dwd层的表也是使用了分区表，做了压缩，还采用了列式存储，列式存储会更加紧密一点，压缩比会更高

# 列式 存储展开？





然后介绍下dwd层的建模 37:26

这一层的建表也是进行了分区和压缩，目前与之前提到的相同。

# parquet展开？

# 建模，星型模型展开？

依据星型模型的建模，需要对维度进行维度退化。关于维度表，商品相关的有sku，spu，商品分类有三级，品牌表，平台属性表，商品属性表等，销售属性表

地理相关的，地区，省份表退化成一张地区表

活动相关的活动信息表，活动规则表，优惠券表，退化成活动维度表

然后考虑建模的四大步骤，

​	①就到了选择业务，由于公司不大，就选择了全部同步维度表

​	②声明粒度，我们是主要考虑最小粒度，这样之后聚合会比较灵活

​	③确定维度，遵循的是何时何地何人对何物 因此考虑了时间，地区，用户，商品，活动，优惠券

​	④确定事实，关注事实的度量值。

# 考虑构建业务总线矩阵，

将事实表和维度表关联起来，以此确定度量值，比如件数，个数等 （花时间较多）



接下来到了dws层和dwt层，dws是按天汇总，dwt是按一段时间来汇总

这两层主要考虑的问题有二，一是宽表怎么设计，要有那些宽表

# 二，宽表的字段要有哪些？

基本上宽表是和维度挂钩的，我们最后是决定了6张宽表

例如地区主题宽表，用户主题宽表，商品主提宽表等

至于字段，要考虑的原则是站在维度的角度考虑事实的度量值

比如商品主题宽表，它会和哪些维度表发生关联，例如和订单详情表，可以有某个商品被下单多少次？每个商品在单比订单中出现的次数等？以这样的考虑维度和事实表之间会产生哪些度量值以此确定字段

​	

在dwt层中可能在dws层的基础上字段更多，因为我们会关注不同指标的开始时间，结束时间，以及这期间和近期的度量值

例如商品会有首次下单时间，最后一次下单时间，商品在不同地区的单天销售额，单月销售额等等



最后一层ads层，一些指标结果，我分析过。。。

手写指标

分类：



访客相关

当天内如下指标是写在一张表里的：

|                                       | 实现思路                          |
| ------------------------------------- | --------------------------------- |
| SessionId                             | 最初构建数仓没有读，需要用sql实现 |
| 新老标识                              |                                   |
| 最近1天                               |                                   |
| 最近7天                               |                                   |
| 最近30天                              |                                   |
| 渠道                                  |                                   |
| 日活(访问人数)                        |                                   |
| 页面停留总时长                        |                                   |
| 一次会话，页面停留平均时长,单位为描述 |                                   |
| 页面总浏览数                          |                                   |
| 会话次数                              |                                   |
| 跳出数（只有一次访问行为的会话）      |                                   |
| 跳出率                                |                                   |

SessionId

使用窗口函数 last_value() 

该函数是取该列最后一个值，可以传入布尔参数来规定是否跳过null值

```sql
last_value(session_start_ts,true) over(partition by mid order by ts)
```

页面停留总时长

按照sessionId分组，求sum（during_time）

```sql
sum(during_time)  count(*) page_counter_per_session
```

最近1天活跃

```sql
count（distinct split(sessionId,'-')[0]）
```

最近7天活跃

```sql
select
count（distinct split(sessionId,'-')[0]）
from
(
select
    mid等字段
from dwd_page_log
where dt > datesub(dt,7)
)
```

最近30天活跃

```sql
from dwd_page_log
where dt > datesub(dt,30)
```

跳出数

```sql
sum(if(page_count_per_session=1,1,0))
```

以上结果union all得到最终结果

跳转路径相关

| 指标           | 备注 |
| -------------- | ---- |
| 最近天数1,7,30 |      |
| 跳转起始页ID   |      |
| 跳转终止页ID   |      |
| 跳转次数       |      |

桑基图：统计每个跳转阶段的人数

​	是DAG

从dwd_page_log取出lastPageId和pageId，炸开表分别做为1，7，30 recentDay

并求出sessionId，依据sessionId和recentDay分组，利用row_number对单次会话的访问路径打上标签记为rn

取出pageId作为source，lead(pageId,1,null) over(PARTITION by session_id,recent_days order by ts ) 作为 target

利用concat拼接source和target以及相对应的step

```sql
   concat('step-',rn+1,':',target) target
```

根据sessionId和

比较难的指标：

留转G复活指标：

1 活跃

​	日活：100万 周活是日活的1.1-1.3倍 月活：是日活的2-3倍 300万

​	总注册用户在1000万-3000万之间

2 GMV 

GMV:每天10万订单 （50 -100元）500-1000万

纯利10-20%  100-200万 除去公司日常开销

3 复购率

日用品的复购率较高 10-20%

高价品，电子产品，手表复购率低 1%

4 转化率

商品详情页 to 加购物车 to 下单 to 支付

转换率会依次提升（大概率）比例降低的话可能是出了问题

5 留存率

1,2,3天 周留存 月留存

搞活动：10-20%

# 指标展开？



结束了ads层分析之后，我们把数据导出到了mysql，再做后期的一个页面展示

仍然使用sqoop导出

也考虑直接存textFile，指定使用/t作为分隔符，这样使得ads统计的结果是一个TSV文件，直接从hdfs下载，放入数据可视化，有多个指标一张表，也有一个指标一张表

# sqoop失败重复问题展开？



最后的页面展示我们使用了superset

# superset展开？

关于日常的临时指标查询，我们起初也是对市面上流行的工具进行了学习，例如

# presto，impala，kylin（针对dwd层）等

kylin需要把它的cube数据存在hbase



整个数仓是依托于hive的，

# hive展开？

## 数据压缩算法

列式存储给数据压缩也提供了更大的发挥空间，除了我们常见的snappy, gzip 等压缩方法以外，由于列式存储同一列的数据类型是一致的，所以可以使用更多的压缩算法。

压缩算法

使用场景

 Run Length Encoding

重复数据

Delta Encoding

有序数据集，例如 timestamp，自动生成的 ID，以及监控的各种 metrics

Dictionary Encoding

小规模的数据集合，例如 IP 地址

Prefix Encoding

Delta Encoding for strings

## 性能

 Parquet 列式存储带来的性能上的提高在业内已经得到了充分的认可，特别是当你们的表非常宽（column 非常多）的时候，Parquet 无论在资源利用率还是性能上都优势明显。具体的性能指标详见参考文档。

Spark  已经将 Parquet 设为默认的文件存储格式，Cloudera 投入了很多工程师到 Impala+Parquet  相关开发中，Hive/Pig 都原生支持 Parquet。Parquet 现在为 Twitter 至少节省了 1/3  的存储空间，同时节省了大量的表扫描和反序列化的时间。这两方面直接反应就是节约成本和提高性能。

如果说 HDFS 是大数据时代文件系统的事实标准的话，Parquet 就是大数据时代存储格式的事实标准。

Parquet 是面向分析型业务的列式存储格式，由 Twitter 和 Cloudera 合作开发，2015 年 5 月从 Apache 的孵化器里毕业成为 Apache 顶级项目，最新的版本是 1.8.0。

## 列式存储

列式存储和行式存储相比有哪些优势呢？

1. 可以跳过不符合条件的数据，只读取需要的数据，降低 IO 数据量。
2. 压缩编码可以降低磁盘存储空间。由于同一列的数据类型是一样的，可以使用更高效的压缩编码（例如 Run Length Encoding 和 Delta Encoding）进一步节约存储空间。
3. 只读取需要的列，支持向量运算，能够获取更好的扫描性能。

当时 Twitter 的日增数据量达到压缩之后的 100TB+，存储在 HDFS 上，工程师会使用多种计算框架（例如  MapReduce, Hive, Pig 等）对这些数据做分析和挖掘；日志结构是复杂的嵌套数据类型，例如一个典型的日志的 schema 有 87  列，嵌套了 7  层。所以需要设计一种列式存储格式，既能支持关系型数据（简单数据类型），又能支持复杂的嵌套类型的数据，同时能够适配多种数据处理框架。 