我读研之前是在北京的易天新动公司做大数据开发岗位，我刚去的时候公司大数据平台处于刚在搭建的阶段，所以也是参与了整个项目的框架选型和一些细节方面的处理

那我先简单介绍下项目的整体框架，数据分日志数据和业务数据

日志数据在日志服务器，来源是前端埋点然后有用nginx做一个负载均衡然后发到基于springboot的日志服务器，然后用flume+kafka+flume的组件做一个数据的采集通道把数据同步到hdfs，业务数据方面是存在mysql，通过sqoop同步到hdfs。同步到hdfs时以load data inpath的方式导入到建好的表形成ods层，整个数仓的架构我们是分ods，dwd，dws ，dwt和ads层。

然后我现在展开来讲一个各个组件的细节

采集端的话flume，flume的主要组成是三个部分，source，channel，和sink。

source我们用的是taildirsource，因为他支持断电续传，channel第一层我们是用了kafka channel，他支持的channel还有file 和memory，m是纯内存的，很快但是可靠性低，单批次支持100条消息，也对饮的如果丢数据是丢100条，file channel 是有罗盘，单批次支持100w条，所以如果挂了极端情况下是丢100w条，kafkachannel 一般在sink是kafka的时候使用，由于flume支持no sink 和 no source的  kafka  channel 写入kafka是事务性的

我们之所以在两层flume中间加了kafkaa是考虑到高峰期晓峰和解耦的一个问题，峰值数据量可能达到2000条每秒，这样的话读写同步hdfs一般承受不住，加入kafka可以达到缓冲的目的并且也可以让hdfs写入不必同步

数据到了ods层之后我们是由设计分区表按天分区，也做了数据压缩采用的的lzo，也采用了列式存储parquet， ods层主要是数据备份，没有做过多的操作，哦这里忘记提到的是我们第二层flume使用了自定义拦截器，对数据做了简单的清洗，自定义拦截器的步骤是继承intercept接口，重写四个方法依次是初始化，单个时间处理，多个事实处理方法，和close方法

然后到了dwd层，dwd层主要做的事情是，分区，压缩，列式存储，数据清洗，例如一些需要计算的字段如果有null值改为0，数据的脱敏例如手机号等，dwd层的建模使用的是雪花模型，呈现的状态多是星座模型，分维度表和事实表，维度表要降维，

dws层主要是一些指标的轻度聚合，按天聚合，



dwt层主要是更大时间间隔的聚合例如1天 7天 30天



ads层主要就是一些指标的实现，我分析过得指标例如

当日新增，

当日新增的计算方法是当日活跃left join 昨日活跃 left join 昨日新增，昨日活跃和昨日新增的字段都为null的mid

留存，

昨日新增left join 今日活跃

回流，



7天内连续三天访问，

周活跃表按照mid分组，组内按照时间排序，开窗用row number，然后计算日期和rank之间的排名查，然后把count每个用户差值相同值数目大于等于三的统计出来 