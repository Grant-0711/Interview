现在我先介绍一下之前做的实时项目

数据来源分为两大类，日志数据和业务数据，日志数据来源是日志服务器自定义kafka生产者发送到kafka，业务数据主要是mysql的业务表数据，大概三十多张表

关于业务数据的同步方式我们当时也是进行了调研选择了几个方案，例如flink自带的cdc，sqoop和maxwell等，初期调研的比较多的是flinkcdc，结果发现如果用flink sql的方式读的话只能单张表单张表的读，如果用流式api读的话拿到的数据除了数据本事还有一些其他讯息例如操作的类型等，需要自定义反序列化器来拿到自己想要的数据，比较麻烦，而使用maxwell的话相对而言方便些，主要配置文件中指定要读的库，就可以监控该库下表的增量变化。所以最后是用了maxwell。

完成日志数据和业务数据的同步之后数据都到了kafka，是直接日志数据一个topic，业务数据一个topic。所以要进行分流，那么现在进进入我们架构的dwd层

dwd层主要做的事情是数据的分流，具体来说针对日志数据，消费kafka 的数据，做成流之后，

